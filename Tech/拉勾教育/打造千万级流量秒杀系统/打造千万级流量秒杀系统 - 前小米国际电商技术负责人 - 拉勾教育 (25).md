---
created: 2021-10-12
tags: []
source: https://kaiwu.lagou.com/course/courseInfo.htm?courseId=547#/detail/pc?id=5273
author: 
---

# [打造千万级流量秒杀系统 - 前小米国际电商技术负责人 - 拉勾教育](https://kaiwu.lagou.com/course/courseInfo.htm?courseId=547#/detail/pc?id=5273)


前面我和你介绍了连接池的实现方法，它解决的是频繁建立连接时的网络延迟问题。而这一讲介绍的协程池，主要是为了降低 CPU 消耗。

为什么协程池能降低 CPU 消耗呢？如果直接用协程而不用协程池，将会有哪些开销呢？

根据 Go 语言调度器原理，从协程的创建和销毁过程来分析，协程的开销主要有这几个方面：

1.  协程在创建时分配内存，造成的 CPU 和内存开销；
    
2.  协程在调度时，涉及协程上下文切换的 CPU 开销；
    
3.  协程在结束时涉及资源回收的 CPU 开销。
    

使用协程与不使用协程具体有多大的性能差异呢？我们可以先通过性能测试来对比下。

### 协程性能测试

为了方便性能测试，我定义了一个 testTask 结构体，并实现了一个 Do 方法，以及一个创建 testTask 的函数 newTestTask。其中，我们在 testTask 中使用了 sync.WaitGroup 来同步任务状态。为了实现内存性能测试，我还实现了一个 newMemTask 函数来创建用于内存测试的任务。具体代码如下：

```
type testTask struct {
   wg *sync.WaitGroup
   ch chan struct{}
   m  bool
}
func (t *testTask) Do() {
if t.m {
      <-t.ch
   }
   t.wg.Done()
}
func newTestTask(wg *sync.WaitGroup) *testTask {
return &testTask{
      wg: wg,
   }
}
func newMemTask(ch chan struct{}, wg *sync.WaitGroup) *testTask {
return &testTask{
      wg: wg,
      ch: ch,
      m:  true,
   }
}
```

为了方便编写测试代码，我实现了一个 runTest 函数，用于不同方案之间复用测试代码。代码如下：

```
func runTest(b *testing.B, f func(i int, wg *sync.WaitGroup)) *sync.WaitGroup {
   runtime.GC()
   b.ReportAllocs()
   b.ResetTimer()
   wg := &sync.WaitGroup{}
   wg.Add(b.N)
for i := 0; i < b.N; i++ {
      f(i, wg)
   }
var memStats runtime.MemStats
   runtime.ReadMemStats(&memStats)
   b.ReportMetric(float64(memStats.HeapInuse)/(1024*1024), "heap(MB)")
   b.ReportMetric(float64(memStats.StackInuse)/(1024*1024), "stack(MB)")
   b.ReportMetric(float64(memStats.StackInuse+memStats.HeapInuse)/(1024*1024), "total(MB)")
return wg
}
```

runTest 函数大致分为三部分：

第一是初始化部分，主要是回收内存、性能测试参数以及 sync.WaitGroup；

第二是执行测试部分，主要是执行从函数参数传入的任务函数，不同方案的执行函数不同；

第三是结果输出部分，主要是输出堆内存、栈内存、总内存的使用信息。

接下来我们实现使用协程和不使用协程时的性能测试函数：BenchmarkGoroutineMem、BenchmarkGoroutineCPU 和 BenchmarkNoGoroutine 。在 BenchmarkGoroutineMem 和 BenchmarkGoroutineCPU 中我们通过协程来执行任务。代码如下：

```
func BenchmarkNoGoroutine(b *testing.B) {
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
      t := newTestTask(wg)
      t.Do()
   })
   wg.Wait()
   b.StopTimer()
}
func BenchmarkGoroutineCPU(b *testing.B) {
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
go func() {
         t := newTestTask(wg)
         t.Do()
      }()
   })
   wg.Wait()
   b.StopTimer()
}
func BenchmarkGoroutineMem(b *testing.B) {
   ch := make(chan struct{})
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
go func() {
         t := newMemTask(ch, wg)
         t.Do()
      }()
   })
close(ch)
   wg.Wait()
   b.StopTimer()
}
```

以上代码都在 infrastructure/pool/worker\_test.go 中。我们执行 go test -bench 命令，输出结果如下所示：

![Drawing 0.png](https://s0.lgstatic.com/i/image6/M00/00/82/CioPOWAaQNeAFMmoAAGyOlI-7Rk714.png)

从结果我们可以看到，无论是 CPU 还是内存，使用协程比不使用协程都高不少。

因此，在高并发场景下，为了追求极致性能，我们有必要用协程池来处理任务，而不是每个任务都创建一个协程来处理。

协程池的实现方法大致有**抢占式**和**调度式**这两种，接下来我给你详细介绍下。

### 抢占式协程池

抢占式协程池的主要原理是：多个协程共享一个任务池，所有任务都放到共享任务池中，每个协程自己去任务池中抢任务并执行。

由于协程池的主要工作是执行任务，为了实现协程池，我们需要先定义好任务的类型。比如这里我定义了一个 Task 接口类，它主要包含一个用于执行任务的 Do 方法。然后我定义了一个 Worker 接口类，它包含一个用于往任务池中推送任务的 Push 方法，以及一个用于关闭协程池的 Close 方法。代码如下所示：

```
type Worker interface {
   Push(t Task) bool
   Close() error
}
type Task interface {
   Do()
}
```

接下来，我定义了 worker 结构体，它主要包含这几个字段：协程数 number、任务池大小 size、关闭状态 closed、任务池 taskPool 以及用于状态同步的 wg。并且，我实现了一个 NewWorker 函数来创建 worker 对象。在 NewWorker 函数中，主要是初始化 worker 的任务池以及各个协程，并调用 worker 的私有方法 run 让协程处于接收任务的状态。代码如下：

```
type worker struct {
   number   int
   size     int
   closed   int32
   taskPool chan Task 
   wg       sync.WaitGroup
}
const (
   minBufferSize = 10
   minNumber     = 2
)
func NewWorker(number int, size int) Worker {
if number < minNumber {
      number = minNumber
   }
if size < minBufferSize {
      size = minNumber
   }
   w := &worker{
      number:   number,
      size:     size,
      taskPool: make(chan Task, size),
   }
   w.wg.Add(number)
for i := 0; i < number; i++ {
go w.run()
   }
return w
}
func (w *worker) run() {
defer w.wg.Done()
for task := range w.taskPool {
      w.process(task)
   }
}
func (w *worker) process(t Task) {
defer func() {
if err := recover(); err != nil {
         logrus.Error(err)
      }
   }()
   t.Do()
}
```

然后，我实现了它的 Push 方法和 Close 方法。在 Push 方法里先判断协程池是否已关闭，如果已关闭直接返回失败；没关闭就将任务推入任务池中，并返回成功。在 Close 方法中，先判断协程池是否已关闭，如果没有关闭就将状态变为已关闭，并关闭任务池，等待所有任务处理完；如果已关闭，则直接返回。**注意，在判断和变更状态的时候使用原子操作，避免并发访问时状态不一致的问题。** 代码如下：

```
func (w *worker) Push(t Task) bool {
if w.isClosed() {
return false
   }
   w.taskPool <- t
return true
}
func (w *worker) Close() error {
if !w.isClosed() && atomic.CompareAndSwapInt32(&w.closed, 0, 1) {
close(w.taskPool)
      w.wg.Wait()
   }
return nil
}
func (w *worker) isClosed() bool {
return atomic.LoadInt32(&w.closed) == 1
}
```

以上便是抢占式协程池的实现，它的代码很简洁。

### 调度式协程池

调度式协程池的原理又是什么呢？当我们的程序中存在多种任务时，任务之间会有优先级之分。比如慢速任务和快速任务对延迟要求不同，它们的优先级也不同，就需要按它们的优先级来调度协程。

因此，我们需要在协程池中能获取任务的优先级，并按照优先级来将任务分配到对应的协程上。这里我定义了一个 PriorityTask 接口类，它比 Task 类多了一个 Priority 方法用于获取优先级。需要注意的是：**优先级越高，表示优先级的数值越小**。

然后，我定义了一个 priorityWorker 结构体，用于实现调度式协程池。它主要包含这几个字段：优先级数量 priorities、每个优先级的协程数量 number、每个优先级的任务池大小 size、各优先级的 worker。像抢占式任务池那样，我也实现了一个函数 NewPriorityWorker 来创建调度式协程池。具体代码如下：

```
type PriorityTask interface {
   Priority() int
   Do()
}
type priorityWorker struct {
   priorities int
   number     int
   size       int
   closed     int32
   workers    []Worker
}
func NewPriorityWorker(number, size, priorities int) Worker {
if priorities < minNumber {
      priorities = minNumber
   }
   number = (number + priorities) / priorities
if number < minNumber {
      number = minNumber
   }
   size = (size + priorities) / priorities
if size < minBufferSize {
      size = minBufferSize
   }
   w := &priorityWorker{
      priorities: priorities,
      number:     number,
      size:       size,
      closed:     0,
      workers:    make([]Worker, priorities),
   }
for i := 0; i < priorities; i++ {
      w.workers[i] = NewWorker(number, size)
   }
return w
}
```

与抢占式协程池不同的是，调度式协程池底层是可以基于抢占式协程池来实现的，仅仅是在上层做了优先级调度策略。因此，它用一个数组 workers 来保存创建好的底层抢占式协程池。

接下来，我实现了抢占式协程池的 Push 方法和 Close 方法。其中 Push 方法差别比较大，它需要从任务中取出优先级，并按照优先级从 workers 中找到相应优先级的 worker。而在 Close 方法中，主要是将状态标记为已关闭，并关闭所有 worker。代码如下：

```
func (pw *priorityWorker) Push(t Task) bool {
if pw.isClosed() {
return false
   }
if pt, ok := t.(PriorityTask); !ok {
return pw.workers[pw.priorities-1].Push(t)
   } else {
      p := pt.Priority()
if p < 0 {
         p = 0
      } else if p >= pw.priorities {
         p = pw.priorities - 1
      }
return pw.workers[p].Push(t)
   }
}
func (pw *priorityWorker) Close() error {
if !pw.isClosed() && atomic.CompareAndSwapInt32(&pw.closed, 0, 1) {
for _, w := range pw.workers {
         w.Close()
      }
return nil
   }
return nil
}
func (pw *priorityWorker) isClosed() bool {
return atomic.LoadInt32(&pw.closed) == 1
}
```

需要注意的是，Push 方法中需要判断传入的任务是否为优先级任务。如果不是优先级任务，则按照最低优先级处理。

### 协程池性能测试

接下来，我们需要对抢占式协程池和调度式协程池做性能测试。

首先，我们需要对之前测试协程性能时的 testTask 做改造，以便支持测试调度式协程池。我们新增 Priority 方法，以及创建优先级任务的函数 newPriorityTask。代码如下：

```
func (t *testTask) Priority() int {
return t.p
}
func newPriorityTask(wg *sync.WaitGroup, p int) *testTask {
return &testTask{
      wg: wg,
      p:  p,
   }
}
```

接下来，我们实现抢占式协程池和调度式协程池的性能测试函数 BenchmarkWorker 和 BenchmarkPriorityWorker。代码如下：

```
const (
   priority = 2
   number   = 2 * priority
)
func BenchmarkWorker(b *testing.B) {
   w := pool.NewWorker(number, b.N)
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
      w.Push(newTestTask(wg))
   })
   w.Close()
   wg.Wait()
   b.StopTimer()
}
func BenchmarkPriorityWorker(b *testing.B) {
   w := pool.NewPriorityWorker(number, b.N, priority)
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
      w.Push(newPriorityTask(i%priority, wg))
   })
   w.Close()
   wg.Wait()
   b.StopTimer()
}
func BenchmarkWorkerMem(b *testing.B) {
   w := pool.NewWorker(number, b.N)
   ch := make(chan struct{})
   wg := runTest(b, func(i int, wg *sync.WaitGroup) {
      w.Push(newMemTask(ch, wg))
   })
close(ch)
   w.Close()
   wg.Wait()
   b.StopTimer()
}
```

抢占式协程池的测试比较简单，就是创建协程池并调用 runTest 函数，使用 testTask 进行测试。而在调度式协程池中，使用了参数 i 为任务生成优先级。最终我们的测试结果如下：

![Drawing 1.png](https://s0.lgstatic.com/i/image6/M00/00/82/CioPOWAaQOyAKSz7AAJbOpHEfaI322.png)

我电脑的 CPU 是 4 个物理核 8 线程，在测试代码中，我将协程池的协程数设置为 4。**从结果中可以看到，在协程池协程数设置为与 CPU 核数接近时，协程池的 CPU 性能要比纯协程的高不少。** 其中，抢占式协程池的 CPU 性能比纯协程高 20%；调度式协程池由于使用了多个 worker，避免了共享任务池的抢锁问题，性能比纯协程高 35%。

在内存测试中，协程池无论是在 CPU 和内存上，都比纯协程好太多。具体来说， CPU 性能是纯协程的 4 倍，内存是纯协程的 1/12。

![Drawing 2.png](https://s0.lgstatic.com/i/image6/M00/00/82/CioPOWAaQPWAdo92AAUJr_3tOHo954.png)

### 小结

这一讲我介绍了协程池的实现原理，以及它们与纯协程的性能对比分析。

需要注意的是，协程池的协程数要根据业务特点合理设置，以便让它的性能达到最优。不合理的设置将会降低协程池的性能。**除了协程数，缓冲区大小也很关键，太小则可能容易阻塞推任务的协程，太大则可能占用较多的内存。** 当你的服务器内存足够的时候，可以考虑使用大的缓冲区来换取 CPU 性能，也就是“空间换时间”。

思考题：

我在实现 Push 方法的时候，用的是阻塞模式，你也可以想想如何用非阻塞的方式实现。期待你在留言区给出自己的答案。

好了，这一讲就到这里了，下一讲我将给你介绍“如何实现用户认证和反黄牛过滤无效请求”。到时见！

源码地址：[https://github.com/lagoueduCol/MiaoSha-Yiletian/tree/main/infrastructure/pool](https://github.com/lagoueduCol/MiaoSha-Yiletian/tree/main/infrastructure/pool)

___

[![1.png](https://s0.lgstatic.com/i/image/M00/6D/3E/CgqCHl-s60-AC0B_AAhXSgFweBY762.png)](https://shenceyun.lagou.com/t/Mka)

**《Java 工程师高薪训练营》**

实战训练+面试模拟+大厂内推，想要提升技术能力，进大厂拿高薪，[点击链接，提升自己](https://shenceyun.lagou.com/t/Mka)！
