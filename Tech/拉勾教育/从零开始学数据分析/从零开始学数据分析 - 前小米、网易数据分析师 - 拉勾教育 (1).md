---
created: 2021-10-11
tags: []
source: https://kaiwu.lagou.com/course/courseInfo.htm?courseId=500#/detail/pc?id=4789
author: 
---

# [从零开始学数据分析 - 前小米、网易数据分析师 - 拉勾教育](https://kaiwu.lagou.com/course/courseInfo.htm?courseId=500#/detail/pc?id=4789)


从今天开始我们一起系统地学习数据分析。

作为一名数据分析师，相信你经常会被问到这样一个问题：“你们数据分析师平时工作都用哪些工具啊？”一般的回答通常是：“数据分析的工具挺多的，但最常用的还是 Excel 和 SQL。”这样的对话虽然对数据分析岗位理解得不算非常到位，但至少对数据分析师必须掌握的基础数据处理技能理解到位了，**基础数据处理技能是成为数据分析师的必要条件**。

数据分析师每天都在和数据打交道，必须精通数据处理技能，才能够提高数据分析的效率，进而扩大数据挖掘和价值探索的边界。

但分析师在面对不同格式的数据时，往往不知道选用哪个工具进行处理最高效。因为数据处理的工具有很多，不同工具都有各自的特点和应用场景。针对这种情况，本课时我先从**重要性、频率、效率**三方面入手，分享 10 个平时工作中的小技巧，来帮助你提升基础数据处理能力。

### Excel 篇

Excel 作为最常用的 Office 办公软件之一，拥有强大的数据处理能力，各行业不同岗位的同学都离不开 Excel。对于数据分析师而言，Excel 更是每天必用的工具。这里我分享两个 Excel 独特且重要的技巧：**vlookup 函数**及**透视表功能**。这两个技巧对数据分析师来说非常实用，而且是 Excel 典型代表，其他数据工具很少有像 vlookup 这样互动性强又便捷的函数。而透视表被很多 BI 工具模仿，因为它靠简单拖曳就可完成数据统计，如果使用得当，可以帮助我们节约不少工作时间，提高工作效率。

#### 巧用 vlookup 函数

vlookup 函数功能，**即通过表格首列查找该函数指定需要查询的值，并返回当前表格中指定列的数值**。函数表达式如下所示：

```
vlookup(查找值，数据表，列序数，匹配条件)
```

下面通过一个案例帮你来理解这个函数。现有一列记录了用户注册省份名称的数据，希望你可以补充省份对应的“省份简称”和“省会城市”数据。这种情况下，如果你没有掌握vlookup 函数，就需要一行行地手动添加，需要处理的数据量少还好说，但如果需要补充的数据源有几十万行，那该怎么办？手动处理会变成一场噩梦。这时，通过 vlookup 函数，就可以瞬间解决这个问题。

**第一步**，我们需要制作一个省份、简称、省会的映射表，如图所示。

![Drawing 0.png](https://s0.lgstatic.com/i/image/M00/59/35/Ciqc1F9xTCmAaPmgAABUPNX4qrw164.png)

**第二步**，添加 vlookup 函数，按照前面我们讲的格式填写 4 个参数，如图所示。

-   第1个参数 M8 指的是要查找单元格的值。
    
-   第2个参数 F:H 指的是要查找的位置。
    
-   第3个参数数字 2，表示要返回的值的区域中的列号。
    
-   第4个参数设置为 FALSE 是表示严格匹配才返回，如果设置为 TRUE 或 1 则表示模糊匹配。
    

接下来只需要复制函数到 N 列的每个对应的单元格，瞬间省份的简称就填写到对应位置上了，见下图。

![1.gif](https://s0.lgstatic.com/i/image/M00/59/4B/Ciqc1F9xYAWAfEDrAGR726s_UP4910.gif)

可以看到，通过上面的操作，我们非常便捷地完成了通过表格首列（即 F 列）查找该函数指定需要查询的值（如"山东省"这个值），并返回当前表格中指定列（即 G 列）的数值（即"鲁"）。这就是 vlookup 函数最常用的一个应用场景。即给出查询内容，在指定区域查询对应内容，然后返回。

下面我们看 vlookup的另外一种应用场景，**连续数值划分区间**。现假设有一列记录了 10 万条 App 用户注册年龄的数据，我们希望能够按年龄段进行划分（比如：0~7 岁、8~18 岁、19~24 岁、25~35 岁、36~50 岁、51 岁以上等），以便统计各年龄段用户的分布情况。面对这样的需求，vlookup 仍然能够轻松实现，下面我们一步步完成数据的统计。

**第一步**，先按需求准备划分的年龄段，输入两列数据。第一列是划分段最小值，第二列填写分段名称，这里要注意上个分段和下个分段的**数据连续性**，即下个分段最小值是上个分段最大值加 1。以“0~7 岁”为例，“0”为该分组下限，“7”为下个分组上线减 1。

**第二步**，输入 vlookup 函数， 填写 4 个参数，然后按回车键就会输出正确的结果，如图所示。

![2.gif](https://s0.lgstatic.com/i/image/M00/59/56/CgqCHl9xX8CAWhBBAIBogYCv9Bg504.gif)

上面介绍了两个 vlookup 常用案例，也是数据分析师日常处理数据经常遇到的场景，一个快速匹配，一个是连续数值分段。工作中，使用 vlookup 函数的场景我们经常遇到，希望你能够活学活用，利用它实实在在地提高我们的工作效率。

#### 巧用透视表

接下来我们学习第二个技巧。同 vlookup 函数一样，透视表在我们的工作中也非常的重要。你可以把透视表理解为数据处理的"最后一公里"，它可以很方便通过鼠标“点点点”完成数据的分组统计、排序、求平均、行列计算占比等常用数据分析功能，并且如果原始数据更新，透视表的数据也会同步更新。这对我们进行数据分析整理无异于提供了一个便捷的工作方式和手段，下面我们通过一个例子来介绍 Excel 透视表的常用功能。

![屏幕快照 2020-09-28 12.32.47.png](https://s0.lgstatic.com/i/image/M00/59/5F/CgqCHl9xbT2ALDAjAATsM9kU_PM955.png)

数据源包括 4 列数据，分别是用户注册 ID、性别、省份、App 使用时长。我们希望了解该 App 对不同性别用户的吸引力，以及女性用户在不同地区的覆盖情况。我们看透视表如何完成分析目标。

针对这个目标，我们可以统计下面两个数据：

1.  不同性别用户数量差异、人均 App 使用时长、总使用时长占比；
    
2.  女性用户在不同省份的数量、女性用户人均 App 使用时长，以及女性用户总使用时长占比。
    

**第一步，生成透视表。** 使用Ctrl+A 快捷键，将数据源全部选中，然后点击菜单栏“插入”->“数据透视表”。

你可以看到透视表主要包括字段列表、透视表区域，以及筛选器等，三者有着不同的作用。

![Drawing 5.png](https://s0.lgstatic.com/i/image/M00/59/44/CgqCHl9xTtiAUd39AAN3M5fgbV0575.png)

**第二步，将“性别”字段拖入“行”区域。将“App 使用时长”字段拖入两次到“值”区域，** 第一次，将值字段设置为求平均值；第二次，将值字段设置为求和。

![屏幕快照 2020-09-28 12.36.30.png](https://s0.lgstatic.com/i/image/M00/59/5F/CgqCHl9xbc2AYeeAAAPAGNwIi-M989.png)

接下来，单击其中一个弹框左侧“值字段设置”对话框，将值字段设置为想要的汇总字段计算类型，这里一个设置求和，一个设置求平均值。

![屏幕快照 2020-09-28 12.40.41.png](https://s0.lgstatic.com/i/image/M00/59/5F/CgqCHl9xbe2AQqFNAAYUSH7oP-8193.png)

**第三步，统计女性用户所处不同省份的 App 使用时长分布。**这是个**筛选操作**，我们把性别拖入筛选器。然后，再将省份拖入列区域，将 App 使用时长拖入值区域，并设置相应统计方式，我们便可得到想要的结果。

![屏幕快照 2020-09-28 12.45.21.png](https://s0.lgstatic.com/i/image/M00/59/5F/CgqCHl9xbgWAPrYHAAR_173sCSs961.png)

由于透视表出色的数据处理能力及其灵活性、普适性。很多编程语言如 Python 中的 pivot\_table 函数，以及 SQL 中的 pivot 函数，都是模仿的透视表功能。

上面举出了 Excel 经常用到的两个典型技巧，非常有用。但对于数据分析来说，也不过是冰山一角。 Excel 作为数据分析师必备技能，学习的正确方式：动手实践->遇到问题->网上搜索+官网 Help->再实践->记录核心技巧案例，如果能够按照这样的路径相信你很快就能熟练掌握。

### Hive SQL 篇

目前所有大厂数据分析师都在使用 Hive SQL 进行数据分析。所以之后会有一个课时来专门讲解 Hive。在这里，先给你介绍下 Hive SQL 中两个重要技巧：行列互转和 row\_number 函数。这两个技巧在面试中经常被问及，非常的实用。

#### 行列互转

行列互转，在数据处理中比较常见，简单来说，它指的就是把一行拆成多行，或者把多行按照某种条件聚合为一行。这里，我会分别举例说明你在什么工作场景中会用到行列转换，以及如何操作。

**（1）行转列用法。**

假设一个字段是由一个数组构成，实际统计时可能需要把这个数组展开后再进行统计。比如，为解决各类业务问题，算法会针对不同用户进行多种 A/B 实验策略，最后看不同策略中哪一个对解决业务问题有效。

这样，一个用户可能会被很多数据策略命中（如：新客策略、地域策略、女性策略等），这时如果需要查看全体用户被女性策略命中的数据情况，就需要先行转列，之后在筛选出女性策略，再进行统计。

下面看下行转列使用的函数：

```
lateral view explode(split表达式) tableName as columnName
```

tableName 表示虚拟表的名称。columnName 表示虚拟表的虚拟字段名称，如果分裂之后有一个列，则写一个即可；如果分裂之后有多个列，按照列的顺序在括号中声明所有虚拟列名，以逗号隔开。

该函数在 SQL 语言中 from 之后， where 之前使用， 下面通过上面举例的 A/B 测试场景的统计需求，来了解这个函数用法：

```
-- 用户测试数据表如下：
select uid, exp_id_list,pv from test_table2;
-- 输出两列如下：
1000001exp_2001,exp_2002,exp_20033
1000002exp_2011,exp_2012,exp_2013,exp_20155
1000003exp_2001,exp_20022
```

在用户测试数据下加入行转列代码。

```
-- 行转列代码
select uid
, exp_id 
, pv
from test_table2 
lateral view explode(split(exp_id_list,',')) tb as exp_id
```

经过行转列操作之后可以看出，每个 uid 对应的实验 id 都变成了一行：

```
-- 行转列输出如下：
-- 可以看出，每个uid对应的每个实验id都变成一行
1000001exp_20013
1000001exp_20023
1000001exp_20033
1000002exp_20115
1000002exp_20125
1000002exp_20135
1000002exp_20155
1000003exp_20012
1000003exp_20022
```

这样即可找出女性策略的用法。以上为“行转列”功能及使用方法。

**（2）列转行用法**

相比行转列的逆向行为就是列转行。相对来说我工作中遇到行转列的情况更多，但的确也会遇到必须用到列转行的场景，下面我们就通过一个案例具体看下。

假设有一张表，记录的是用户注册 id、用户历史使用的手机型号。我们希望了解用户累计使用过的不同手机型号的用户数分布。

这时，就可以通过列转行后再进行 group by 汇聚统计来处理。测试原始数据如代码所示：

```
-- 测试数据表如下：
select * from test_table1;
-- 输出如下:
1000001mi_6
1000001mi_9
1000002mi_10
1000003mi_9
1000003mix_3
1000005mi_9
1000005mix_3
1000008mi_10
1000009mi_9
1000009mix_3
1000010mi_9
1000010mix_3
1000021mi_8
1000021mi_9
1000023mi_8
1000023mi_9
```

在原始测试数据后加入列转行代码。

```
-- 列转行代码
-- collect_list
select uid
, sort_array(collect_set(phone)) as phone_list
from test_table1
group by uid
```

执行后输出如下所示：

```
-- 列转行输出如下: 
1000001["mi_6","mi_9"]
1000002["mi_10"]
1000003["mi_9","mix_3"]
1000005["mi_9","mix_3"]
1000008["mi_10"]
1000009["mi_9","mix_3"]
1000010["mi_9","mix_3"]
1000021["mi_8","mi_9"]
1000023["mi_8","mi_9"]
```

经过列转行操作之后，用户累计使用过的手机型号就一目了然了。

#### row\_number 函数

row\_number 函数的功能是为了将分组统计后的每组数据取 TopN 输出。这个功能对我们来说非常实用。

比如，我们分组汇总各行业大客户的充值金额并排序后，很自然希望看到每组数量 Top 客户的情况，目的是及时掌控头部客户的信息，以服务好大客户，使其能够长久为公司贡献现金流。不少公司面试会专门出类似面试题目，目的就是考察 row\_number 函数用法，也可见其重要性。

下面，我们来介绍 row\_number 函数各参数含义，以及用法。

```
row_number() over(partition by column1 order by colomn2 desc/asc)
```

row\_number 函数先按照 column1 分组， 然后按 column2 降序排列。

```
select * 
, row_number() over(partition by customer_id order by price) as id 
from test_table3
```

接下来针对 test\_table3 按照 id 调用 row\_number 函数。

```
-- 输出数据如下:
-- 第一列客户id， 第二列客户充值金额， 第三列为客户充值金额大小倒序排列的序号
10001100   1
10001300 2
100015003
10001600  4
10003100001
1000320002
100035003
1000415001
1000430002
1000435003
1000450004
1000480005
```

你可以看到输出结果中每个用户 id 为一个分组，每组按客户充值金额倒序排列，并生成第三个字段，即按每组充值金额倒序排列的序号。

学习完 row\_number 函数典型应用场景，能够快速帮助我们组内排序。工作中体现快速高效的实用技巧还有很多，下面再分享些在写 SQL 的过程中会让你眼前一亮的两个小技巧。

#### 巧用 Sublime 写 SQL

Sublime 是一款功能强大的高级文本编辑器，可以安装很多插件满足比如前端开发、Python 后端开发等不同的开发需要。

数据分析师日常也需要使用文本编辑器来编写 SQL 脚本，或者查看数据文件。这里注意，数据分析师用 Sublime 写 SQL 脚本时，经常使用的两个技巧：查找替换和列选。

-   **查找替换**
    

这个功能任何一个编辑器都有，但是 Sublime 对查找支持的更全。比如：正则匹配。

下面举个例子，当要查询某一批用户 uid 的数据时，这时需要将这批用户 uid 用引号和英文逗号分开。

菜单：Find (查找)-> Replace (替换)，然后输入要替换的换行符以及要替换成的'，'。

替换结果如下：

![序列 13.gif](https://s0.lgstatic.com/i/image/M00/59/54/Ciqc1F9xbkaAfiooAIi7rgRyCxs318.gif)

这个结果一般用于 SQL 脚本 in 操作，筛选一批 uid 对应信息。比如：

```
select * 
from test_table3 
where customer_id in ('1000001','1000002','1000003','1000005','1000008','1000009','1000010','1000021','1000023')
```

-   **列选**
    

除此之外，列选也会经常用到，列选后同时操作多行来完成脚本编写。比如：SQL 中 case when 如果要匹配的代码行数很多，但样式类似时，就可以使用列选功能同时编写多行，提升效率。

如下所示， 要针对 customer\_uid 分别给予不同名称， 由于 SQL 结构一样，就可以通过列选后，同时编辑多行：

![序列 10.gif](https://s0.lgstatic.com/i/image/M00/59/54/Ciqc1F9xbmOAY8QaAHQURif1jq4935.gif)

以上两个属于在使用 Sublime 编写 SQL 时经常使用的技巧，当然 Sublime 的强大功能远不止此，它还能安装很多第三方插件完成功能扩展，如果你感兴趣可以到官网深入了解。

### Shell 篇

Shell 脚本因其功能强大，也是数据分析师日常必须掌握的工具，这里我简单介绍一些对数据分析师来说很常用的功能。

#### 批量生成 SQL

身为数据分析师，我们经常会遇到这样的数据分析需求：业务方希望看最近 1 个月内用户某指标数据，并且这个指标是个性化的，导致现有报表无法支撑数据。需要我们手动去跑。

这就存在一个问题：我们计算所需要的表，数据量很大，例如一天日志数据量可能是千亿级别的。这种情况下，我们靠着有限的计算资源，每次统计一天数据，就需要提交 30 个脚本了。

这时，如果相同的 SQL 写 30 遍就太低效了。我们可以通过 Shell 脚本批量生成 30 个 SQL 脚本，让每个脚本计算一天的数据。

举个例子：下面是按天统计的脚本， 我们目的是同时并发运行 30 天数据。

```
dates=$1
hive -e"select count(1) 
from test_table 
where dt=${dates}">out_${dates}
```

下面是同时运行 30 天数据的写法，每 1 行统计 1 天数据，只需要修改日期即可：

```
nohup sh run_template.sh 20200715 &
nohup sh run_template.sh 20200716 &
nohup sh run_template.sh 20200717 &
nohup sh run_template.sh 20200718 &
nohup sh run_template.sh 20200719 &
... ...
nohup sh run_template.sh 20200801 &
nohup sh run_template.sh 20200802 &
nohup sh run_template.sh 20200803 &
nohup sh run_template.sh 20200804 &
... ...
nohup sh run_template.sh 20200813 &
nohup sh run_template.sh 20200814 &
nohup sh run_template.sh 20200815 &
```

巧用 Shell 可以起到事半功倍的效果，数据分析师经常要和 Shell 命令打交道，下面我再分享几个常用的 Shell 命令。

#### 定时任务执行

定时任务，不仅服务器开发同学经常用到。数据分析师也经常使用，比如：我们经常遇到业务方每天要 App 前一天的核心数据。其实，这种情况通过 Shell 设置定时任务就可以轻松解决。这样，我们只需要每天执行统计任务，再定时将数据结果邮件发送给业务方即可。

Linux 定时任务使用 crontab 命令来完成。如下是系统对于 crontab 命令用法的解释。5 个星号表示设定周期执行的颗粒度，分别对应：分钟、小时、天、月、周。

```
cat /etc/crontab
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
```

下面利用 crontab 编写几个定时执行的实例，你一眼就能看明白 5 个"\*"各种的功能定义：

```
30 * * * * sh ~/data/your_run.sh 
30 3 * * * sh ~/data/your_run.sh 
30 3 1 * * sh ~/data/your_run.sh 
30 3 * * 5 sh ~/data/your_run.sh
```

定时任务简单、易用，是用机器解放人力重复劳动的典型应用。尽量将重复劳动的部分抽象出来，在工作中，一定要有这个思维。

#### grep 命令统计

Linux 系统中 grep 命令是用来查找文本中符合条件的字符串。grep 参数有 20 多种，可以满足各类查找的长尾功能需求。我们这里主要介绍几种常见的用法，如果你有时间并且感兴趣可以通过 man grep 命令查看 grep 命令的所有长尾用法。

-   查找文件中包含某字符串的行。
    

```
grep "zhang" yourFileName
grep "北京" yourFileName
grep "[北|京]" yourFileName
```

-   反向查找：查找不含某字符串的行。
    

-   正则查找：根据正则匹配条件查找。
    

```
grep -e "正则表达式" yourFileName
```

-   查找字符不区分大小写：
    

```
grep –i "被查找的字符串" yourFileName
```

grep 是用来完成字符串查找的 Linux 命令，下面来讲如何对满足条件的文本进行编辑的 Linux 命令。

#### sed 命令统计

sed 是一种编辑功能的命令，它可以对满足某种条件的行进行删除，也可以对匹配到的字符进行替换。

比如：文本很大，有成千上万行，但是要删掉第一行标题，这时我们不能选择打开一个这么庞大的文件，然后手动删除，我们只能使用 sed 命令进行删除。而替换的场景也是类似的，而且，sed 能做到批量快速替换。

下面，我们看下 sed 常用命令：

**查找并打印：**

```
sed -n '/9/p' yourFileName
```

**查找并替换：**

```
sed 's/mi/iphone/g' yourFileName
```

**查找并删除：**

```
sed '/9/d' yourFileName
sed -i '/9/d' yourFileName
```

sed 命令功能强大，我们只需要了解其常用的功能，对于长尾的功能和参数， 当用到时再查看帮助文档即可，完全不需要记。

#### awk 命令统计

相比 grep、sed 命令，awk 更像一种高级编程语言，因为它拥有很多内置函数，是 Linux 系统中强大的文本处理工具。

数据分析师必须熟练使用 awk 来处理数据。下面我来举几个我日常使用 awk 完成初步数据统计分析的案例。

-   查询某几列并打印：
    

```
select column_1, column_3 from test_table
awk -F'\t' '{print $1,$3}' yourFileName
```

-   查询某列值大于 100 的行并打印：
    

```
select column_1, column_3 from test_table where column_1>=100
awk -F'\t' '{if($1>=100) print $1,$3}' yourFileName
```

-   统计按某列 group by 分组汇总各组行数并打印：
    

```
select column_1, count(1) as cnt from test_table group by column_1
awk -F'\t' '{a[$1]+=1}END{for(i in a) print i, a[i]}' yourFileName
```

awk 同样还有很多高级用法，其中上面提到 awk 其实就是一门高级语言，配合 Shell 管道命令可以和其他 Shell 命令无缝衔接，可以说威力无穷。
