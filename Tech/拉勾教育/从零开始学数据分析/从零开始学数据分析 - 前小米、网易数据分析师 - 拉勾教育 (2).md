---
created: 2021-10-11
tags: []
source: https://kaiwu.lagou.com/course/courseInfo.htm?courseId=500#/detail/pc?id=4789
author: 
---

# [从零开始学数据分析 - 前小米、网易数据分析师 - 拉勾教育](https://kaiwu.lagou.com/course/courseInfo.htm?courseId=500#/detail/pc?id=4789)


今天我们开始学习使用开源工具 OLAP 助力数据分析。

在数据经济时代，数据价值挖掘是企业发展的新动力。比如，电商平台为了获取更多的订单可能比你自己更了解你的兴趣偏好。短视频平台为了更多地抢占用户使用时长使用智能推荐让你“刷”不停，等等。

互联网大厂通过强大的数据基础建设，让数据分析挖掘的成本变得更低，使公司各个业务线都可以轻松获取数据，让数据赋能业务发展。而基础数据建设从底层到顶层依次包括了数据收集、数据仓库建设和 BI/OLAP。

![图片2.png](https://s0.lgstatic.com/i/image/M00/59/E8/Ciqc1F9y5niAJJVTAADKCNWzyok106.png)

本课时，我们就来分享下处于数据基建顶层的，也就是最接近业务侧数据分析的 OLAP 工具。

### 简单了解 OLAP

#### OLAP 的定义

想要搞清楚什么是 OLAP，我们先要理解“信息数据”这个概念。信息数据是从原始数据中转化出来的，能够真正为用户所理解，并真实反映企业多维度特性的数据。而 OLAP 的官方定义是使分析人员、管理人员或执行人员能够从多种角度对信息数据进行快速、一致、交互存取，从而获得对数据更深入了解的一类软件技术。

我们也可以将其简单理解为是一款帮助分析师从**多个角度分析和挖掘现有数据的工具**。它的目标是满足多维度数据查询和报表需求，核心点是 **“多维度”**。如下图:

![image.png](https://s0.lgstatic.com/i/image/M00/59/F3/CgqCHl9y5oCAKDEeAAJnBhIi_0U123.png)

#### OLAP 的优点

上节课我们也提到了大厂和小厂的区别，本质上是数据基础建设的区别。其中 OLAP 技术的应用，便是产生区别的原因之一。OLAP 技术在大厂应用比较普及，很多小厂则没有这个能力来开发和维护 OLAP。

OLAP 在很大程度上，能够充分降低数据分析的使用门槛，大大降低数据挖掘的成本。即方便数据分析师挖掘数据，又能让不熟悉 SQL 语言的产品、运营等业务同学通过简单的鼠标拖曳完成数据分析。

接下来我们通过对比传统手写脚本处理数据需求和使用 OLAP 处理数据需求的区别，来感受 OLAP 为数据分析师带来的便捷。首先，我们看下传统手写脚本的基本步骤：

1.  明确数据需求和统计口径；
    
2.  锁定统计所需要的数据表和字段；
    
3.  编写脚本，并测试语法正确无误；
    
4.  运行脚本，等待数据结果；
    
5.  任务执行结束，导出数据结果；
    
6.  将结果汇总整理后发送需求方。
    

步骤虽然看起来并不复杂，但在具体操作时即使是对数据处理特别熟悉的同学也需要花费精力按部就班地一步步操作，一步步检查，耗时又费力。

比如，第 2 个步骤中日常统计的数据表可能多达几十张，这时就需要把统计所需的表和字段都找出来，相当费时；第 3 个步骤中如果涉及多个表 join 和限制条件，哪怕是对 SQL 身经百战的我，实际上一次写完运行没有任何问题的情况也不多，等等。在每个步骤中都有可能遇到棘手的问题，特别是对数据表不太熟悉的同学，或是新来的同学，那么他花费的时间可能会更多。

但使用 OLAP 就可以帮助我们规避掉这些问题，OLAP 处理数据需求的大致步骤如下所示：

1.  确定数据需求和统计维度；
    
2.  确认 OLAP 系统统计维度完整；
    
3.  鼠标拖曳维度，像 Excel 透视表一样，瞬间得到计算结果；
    
4.  下载数据结果，直接发送给业务方。
    

你可以发现，使用 OLAP 过程中，不涉及编写脚本。因此也不需要一遍遍测试 SQL 脚本语法是否正确，自然也不涉及表和字段的确认。最重要的是，**OLAP 计算神速**，很快就可以轻松获取统计结果。

OLAP 之所以能够快速处理数据，是因为在搭建 OLAP 时会**提前定义好常用的分析维度**，预计算各维度的统计值，使得数据分析师可以在进行“上卷下钻”时能够将数据加载到内存中快速汇聚统计。

我们举个简单的例子，一张拥有上亿用户的画像表，包括用户 ID、年龄、性别、省份四个字段，其中用户 ID 是不重复的唯一值。这张表作为 OLAP 工具计算的数据源，想要实时计算不同维度的用户数量，就需要每天定时预处理各个维度的用户量。

你可以将预处理简单理解为将该表做类似下面的处理。

```
select age, gender, province, count(1) as cnt
from user_profile
group by age, gender, province
```

上面经过处理后的结果，将即使上亿行的表，也可以缩小为万级别，即: 年龄数 \* 性别数 \* 地域数= 100 \* 2 \* 31 = 6200，即预处理后的数据量，可以大大缩短计算时间。  
相信通过上面的例子，你就可以明白 OLAP 为什么查询那么快了。

### OLAP 主流技术

介绍完什么是 OLAP，以及 OLAP 对于数据分析方面的优势，下面我们来看下各厂都在使用什么样的 OLAP 工具。

这里我重点介绍 3 个 OLAP 工具，它们是目前互联网大厂应用比较广的，也是我自己经常搭建使用的。

-   [Druid](https://druid.apache.org/)：由广告公司 MetaMarkets 开源的实时大数据分析引擎，2011 年创建，并于 2012 年开源。主要用于大规模事件流数据（Event Stream Data）的存储和分析。Druid 被阿里、小米、网易、优酷、微博等公司广泛应用。
    
-   [Presto](https://prestodb.io/)：Facebook 2013 年开源的 OLAP 工具。Airbnb 和 Dropbox、京东、有赞、微博等公司使用该工具。
    
-   [Clickhouse](https://clickhouse.tech/)：第一大搜索引擎 Yandex 开发的列式储存数据库。 ClickHouse 比 Vertica 约快5倍，比 Hive 快 279 倍。比 My SQL 快 801 倍。字节跳动、阿里、微博......几乎所有主流互联网公司，都会使用到 ClickHouse。
    

我们大概了解了目前较为主流的 OLAP 技术，现在让我们再分别看看这些技术的情况。

#### Druid

首先来看看 Druid。Druid 设计之初，是为了满足**PB 级别大数据量的实时数据分析**，设计上借鉴了 Google 数据分析工具 PowerDril，满足**快速查询、水平扩展、实时分析**三个目标。

Druid 之所以能够做到**实时数据分析**，主要有以下原因：

1.  Druid 支持实时数据摄入，且可以立即查询；
    
2.  类似其他 OLAP 工具，摄入数据时先预计算，以节省数据存储量级；
    
3.  列式存储。区别传统行式存储，每次查询要加载整个表，列式存储只需加载指定列数据，大大提升性能。由于列式存储这个优势，目前主流 OLAP 都采用列式存储；
    
4.  水平扩展。可部署到几十甚至几百台集群，支持万亿条记录查询。
    

以上是支持 Druid 做到实时数据分析的主要原因，其他方面，对索引、容错的支持也加强了 Druid 实时查询性能。

我们简单了解了 Druid 为什么在如此大数据量的情况下还能够做到实时查询，对于 Druid 的**数据摄入、数据存储、索引建立**等偏工程细节的问题， 这里不做过多介绍，如果你感兴趣可以到 Druid 官网进行学习。

下面，我再介绍下 Druid 的应用场景。Druid 适合导入数据量大，更新频次少，且要求实时查询的场景。比如，海量用户行为分析、用户画像分析等。Druid 官网列举的应用场景如图所示。

![图片1.png](https://s0.lgstatic.com/i/image/M00/59/F3/CgqCHl9y5qOAHs8FAADlJYA1onM832.png)

在实际使用中 Druid 可用于用户互动行为的**实时数据查询和监控**。比如：衡量运营活动的用户参与度，新旧功能的 A/B Test 数据对比，以及不同渠道用户行为数据等。Druid 的搜索和过滤功能使用户能够快速，轻松地按任意一组属性向下钻取。并根据年龄、性别、地理位置等获取想要统计维度的用户数据。

除了以上通过互动用户界面完成数据统计和展示外，Druid 还支持标准 SQL 查询。当然，Druid 也不是万能的，它并不能完全代替 Hive 查询。举两个例子。

1.  查询中涉及多个大表之间 join，即：Druid对表关联操作支持很有限。
    
2.  数据查询对延时要求不高，但对用户某具体行为颗粒度的场景分析。因为预计算会损失用户行为的个性化信息，所以这种情况是不容许进行预计算操作的。
    

在合适的场景中，Druid 会加速数据价值的运转效率。这里你可以思考下，想一想自己公司的什么业务可以使用 Durid？通过使用 Druid 卓越的实时数据分析能力，我们可以为公司创造什么样的数据价值？

#### Presto

接下来，我们再来了解一下 Presto。Presto 是 Facebook 于 2013 年开源的高性能分布式 SQL 查询引擎，为解决海量日志数据的分析而被开发。

在 Presto 诞生以前，Facebook 数据分析使用的工具是大家耳熟能详的 Hive。但 Facebook 的数据科学家渐渐发现，以 MapReduce 为底层计算框架的 Hive，计算性能和耗时越来越不能满足快速发展的业务数据分析需求。这是因为 Hive 速度太慢了，一个简单的数据查询也需要花费几分钟或者长达几个小时。

基于数据科学家的快速查询数据的强烈需求，Facebook 经过长期的调研和试用，却没有找到合适自身业务分析需求的 OLAP 工具。于是在 2012 年，Facebook 决定自己开发，并在公司内部推广使用，由此 Presto 也就诞生了，Preso 的性能要好于 Hive 10 倍。

我们先来简单了解下 Presto 设计架构，这将有助于你理解其优势、劣势和应用场景。Presto 使用的是和其他大数据处理引擎相同的架构：**Master-Slave 架构，即主从架构**。架构上分为大概四部分，我们先了解下这四部分的主要内容。

-   Coordinator：即 Presto Master。我们可以将其简单理解为“包工头”。外面揽活，搞到"计算"任务后，将任务拆分给工人。
    
-   Worker：即 Presto Slave 。简单理解为干活儿的工人，从包工头那里分配到"计算"任务，负责把活儿干好后（计算后的结果数据），返回给包工头，即 Master。
    
-   Discovery Service：保存 Worker 结点信息。
    
-   Connector：连接器。包括 Hadoop 或 MySQL 等组件的连接器，负责实际执行查询任务。
    

![image (1).png](https://s0.lgstatic.com/i/image/M00/59/E8/Ciqc1F9y5rOAA4I_AAENKQXIHcU166.png)

我们再来了解一下 Preso SQL 的**运行过程**，主要分为四步：

1.  Coordinator 接到 SQL 后，通过 SQL 脚本会被解析成语法树，这个过程同时会 check SQL 语法，如果有错误会在此暴露，并结束查询任务；
    
2.  SQL 语法没问题，会通过 Connector 查询 metadata（元数据），即 SQL 里查询的哪张表的哪些字段，以及字段类型，如果发现 SQL 字段类型错误同样会返回停止查询任务；
    
3.  经过上面两个步骤后，SQL 脚本最终被映射了一个查询计划，并被分发到逻辑计划查询器中， 从而转化成多个 task 任务；
    
4.  task 将数据信息解析后，返回给查询计划，最后 task 会被分到各个分布式的机器（Worker）实际执行。
    

讲完 Presto 架构设计和运行步骤，我们了解下 Presto 特点和优势。

1.  快！Presto 最大的特点是快，它的设计初衷是解决快速查询大数据问题，期望查询时间是在几秒或者几分钟，因此速度是 Hive 的 10 倍以上；
    
2.  Presto 可以查询完全基于内存计算的分布式 SQL 查询引擎。所有查询、计算都可以在内存中进行；
    
3.  Presto 可以接入数据源，包括 Hive、Kafaka、MySQL、Redis 等；
    
4.  Presto 为标准 SQL，支持复杂 SQL 查询。
    

看完上面的 Presto 的优势，你可能会产生一个疑问， Presto 大数据处理性能这么优秀，为什么没有完全替代 Hive？为什么目前 Hive 依旧是应用最广的大数据离线处理工具？

回答这个问题，就要了解一下 Presto 的缺点和适应场景了。下面，我说下 Presto 一些缺点，上面的疑问就会得到解答。

1.  我们知道 Presto 运算时是将查询任务拆分到多个 Worker 机器上去分别进行内存运算。其中哪怕一个 Worker 由于各式各样的原因挂掉（比如内存溢出等），整个 Presto 查询任务就会失败。相比较而言，Hive 的容错性能就要好很多。一台机器挂掉或者被其他计算任务抢占，计算也并不会因此失败。它会重新向 Master 申请资源，继续计算。
    
2.  Presto 属于纯内存计算，不适合大表之间的多表 join 操作。否则容易引起内存溢出 OOM，造成查询任务失败。
    
3.  Presto 采用 MPP（Massively Parallel Processing：大规模并行处理）架构，本身 MPP 架构使用场景就是秒级、毫秒级的查询场景，速度很快。但 MPP 有个明显缺点，即**短板效应**。如果一个 Worker 节点计算慢于其他节点，那整个计算任务都会受限于该节点。在实际工作中，Presto 接入的很可能就是 HDFS 数据源，不同节点的数据不一定分布均匀，这使得不同 Worker 干活效率不一样。而 Hive、Spark 等采用的批处理系统则会避免这一点。
    

由此可见，Presto 既有优点又有缺点。那么什么样的应用场景适合 Presto 呢 ？经哥在工作中发现，下面两个场景对 Presto 来讲最为合适。

1.  满足数据分析师**临时查询需求**，希望查询结果在几秒到几分钟内快速返回，这样的场景是适合 Presto 的。如果查询超过半小时，那说明该查询不适合 Presto 计算场景。
    
2.  支持 PB 级别查询需求，但不适合大表之间 join 操作的场景。用几个百亿级别大表进行 join 的复杂操作，可能使得 Presto 几十分钟没有结果，甚至挂掉。这样的计算任务可以交给 Hive 或者 Spark 等批处理分布式计算引擎完成。
    

Presto 相比上面介绍的 Druid，主要是解决 SQL 查询引擎的问题，将 SQL 查询转换成分布式任务，快速到数据存储区获得必要的数据，并且返回结果。Presto 直接访问 HDFS 或者其他数据存储层，并没有像 Druid 那样优化存储结构。它无法将原始数据进行预计算后建立索引并存储。

但好处是保留数据全部的数据信息，在计算性能满足的条件下，可以支持所有数据的行粒度信息查询。而 Druid 是在一定程度上提前设计分析常用的维度，压缩数据并存储，这个必然牺牲一些数据的个性化信息，目的是满足核心指标的快速上卷下钻，但对一些个性化 case 数据无法兼顾。

#### ClickHouse

我们再来了解一下 ClickHouse。ClickHouse 是俄罗斯 Yandex（号称俄罗斯 Google）在 2016 年开源的⾼性能分析型 SQL 数据库，主要面向 OLAP 场景。ClickHouse 凭借优异的查询性能，在互联网各大厂广泛应用，包括阿里、腾讯、字节、快手、携程、贝壳等。

ClickHouse 作为一颗新星，将大数据处理效率发挥到了极致。在数据存储和计算方面，它没有使用 Hadoop 生态，而是采用 Local Attached Storage 作为存储（即本地附加存储），这样使得整个数据 I/O（数据的输入和输出）从根本上被消除了。而基于 Hadoop 生态的大数据处理，从而引起的磁盘 I/O 占据整个数据处理的时间和资源。

ClickHouse 拥有以下三点优势。

1.  **提供极致的查询性能**。比传统数据处理引擎快 100~1000 倍，数据吞吐能力高达50MB~200MB/s。使用体验非常好。
    
2.  **大数据的极低存储成本**。ClickHouse 针对 OLAP 场景，开发高效列式存储、数据压缩算法，可以将原数据压缩 10 倍，极大提高单机数据存储和计算能力。可以简单理解为，原来一台机器存储 1TB 原始日志，而采用 ClickHouse 可以存储 10TB 原始日志。
    
3.  **支持 SQL 查询**，并同时支持 join 等复杂计算逻辑。ClickHouse 之所以能拥有极致的计算性能，即使简单的查询，ClickHouse 也会使用服务器一半的 CPU 去执行，所以其充分利用了机器的计算资源，并实现单机多核并行计算、集群分布式计算、列存储且列计算等。
    

同样，ClickHouse 也存在着自己的劣势。ClickHouse 的劣势主要体现在两点上。

1.  不支持事务操作，即数据的删除、更新。
    
2.  不支持高并发，建议 QPS 为 100。即每秒查询操作不要超过 100 个。
    

但对于 OLAP 应用场景， 其劣势正好显得不那么重要，我们使用时更注重其在大数据处理上的优势。因为 OLAP 查询一般为历史数据，很少变更，另外作为公司内部数据分析和产品人员使用，人数不会太多，同时每秒 100 个查询足够满足要求。

ClickHouse 也有一些合适的应用场景，在**实时计算**时，数据流通过 Kafka 或者 Flink 实时处理之后，通过 JDBC 方式批量导入 ClickHouse 中。在**离线计算**时，数据落地 HDFS ODS 层，离线通过 Spark 或 MR 的 batch 形式批量导入 ClickHouse 中。

ClickHouse 起步晚，但是作为大数据领域后浪发展迅猛。在公司中，ClickHouse 能为业务方，包括数据分析师、产品、运营、运维等提供高效数据 OLAP 查询，让业务方更快更高效的获得想要的数据，极大提升了数据价值挖掘。

### 总结

本课时主要介绍了 Druid、Presto、ClickHouse 这三个 OLAP 技术。可以看出，相比 Hive、Spark 等大数据计算引擎，它们的共同特征就是让数据查询变得更简单、更快速！秒级甚至毫秒级！但为了达到快速查询的目的， 它们也在其他方面做出牺牲。这并没有影响它们被广泛应用。作为数据分析师，在数据分析和处理过程中，都希望能够压缩数据处理的时间，如果有更快速且满足业务分析需求的工具和技术，必然是首选。

OLAP 就是这样的一种技术，满足数据分析师快速查询需求。希望通过本课时的学习，让你在简单了解各大厂应用的主流的 OLAP 技术的同时，能够深刻认识到 OLAP 在数据分析过程中的发挥的重要作用。
