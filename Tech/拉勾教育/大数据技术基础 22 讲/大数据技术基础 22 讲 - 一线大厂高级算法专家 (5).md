---
created: 2021-10-11
tags: []
source: https://kaiwu.lagou.com/course/courseInfo.htm?courseId=615#/detail/pc?id=6512
author: 
---

# [大数据技术基础 22 讲 - 一线大厂高级算法专家- 拉勾教育](https://kaiwu.lagou.com/course/courseInfo.htm?courseId=615#/detail/pc?id=6512)


在前面的章节里，我们多次提到了 Hadoop 这个名称，想必你也大概知道了 Hadoop 是一个用于大数据的架构解决方案。关于 Hadoop 的理论基础以及是如何诞生的，我们在[《02 | 从萌芽到爆发，大数据经历了哪些发展》](https://kaiwu.lagou.com/course/courseInfo.htm?courseId=615#/detail/pc?id=6514)中做了简要的介绍。那么，这一讲我们就从整体上来看一下 Hadoop 到底是怎样的。

### Hadoop 的整体架构

经过了这么多年的开发与演进，Hadoop 早已成为一个庞大的系统，它的内部工作机制非常复杂，是一个结合了**分布式理论与具体的工程开发的整体架构**。对于没有什么经验的人来说，Hadoop 是极其难理解的。不过，我们这一专栏并不是要把 Hadoop 的运行机理讲清楚，而是明白 Hadoop 为我们提供了什么样的功能，在我们整个大数据流转的过程中可以发挥哪些作用就可以了。

关于 Hadoop 最朴素的原理，就是要使用**大量的普通计算机处理大规模数据的存储和分析**，而不是建造一台超级计算机。这里有两个问题需要解决。

-   **计算机的故障问题**。想象我们使用一个有一万台计算机组成的集群，其中一台计算机出现问题的可能性是很高的，所以在大规模计算机集群上要处理好故障问题，就要做到一台计算机出现问题不会影响整个集群。
    
-   **数据的依赖关系**。集群由若干台计算机组成，数据也是分布在不同的计算机上面，当你需要计算一个任务的时候，你所需要的数据可能要从若干台计算机进行读取，而你的计算过程也要分配到不同的计算机上。当你的任务分成若干个步骤形成相互依赖的关系时，如何让系统保持**高效和正确的运行**是一个很大的问题。
    

下图是 Hadoop 系统的一个架构图，虽然现在已经有了非常多的组件，但是其中最核心的两部分依然是**底层的文件系统 HDFS**和**用于计算的 MapReduce**。接下来，我们来看一下 Hadoop 系统中的一些重要组成部分。

![图片1.png](https://s0.lgstatic.com/i/image6/M00/04/51/CioPOWApKLSADWyAAAD6GUS5zaE125.png)

#### 1.HDFS（分布式文件系统）

HDFS 是 Hadoop Distributed File System 的缩写，从名字就可以看出它是一个文件系统。它在 Hadoop 体系中帮助解决文件的**底层存储问题**，能够用来支持海量数据的磁盘存储，能够进行机器的线性扩充，只需要在集群中增加节点，存储能力就会同步增长。

不仅如此，HDFS 还具备非常**强大的容错性能**，其中的某些节点出现了故障不影响系统的使用，通常数据都有很多的副本。HDFS 屏蔽了那些存储的细节，并在客户端为大家提供了一套完整的文件管理命令，把底层的文件以一种结构化的目录形式展现给用户，我们可以像使用 Linux 文件操作命令一样使用 Hadoop 命令来访问对应的文件。

#### 2.MapReduce（分布式计算框架）

思考一下我们刚刚进行过的**人口普查**，先把这个大任务按照地区划分成若干个小任务，每个地区找一名负责人，确保地区的划分不重不漏。然后由这个地区的负责人负责统计自己区域内的人员数量等信息，然后把所有人的统计结果汇总起来，就能得到全国的人口普查数据。如果说其中一个负责人有事情，不能完成，就可以换一个人继续进行这个地区的统计，而不会明显地影响全国的人口普查进度，这其实就是最朴素的 MapReduce 思想了。

在 Hadoop 中的 MapReduce 框架就解决了**分布式计算**的问题，包括其中的**运算逻辑**与**数据依赖**。在 MapReduce 的应用上，提供了一套编程模型，重点就是实现 map 函数和 reduce 函数：

-   map 函数用于组织和分割数据；
    
-   reduce 函数主要负责在分布式节点上的数据运算。
    

MapReduce 编程支持多种语言实现，比如 Java、Scala 等。

#### 3.Hive（数仓系统）

在 HDFS 之上，Hive 是 Hadoop 体系的**数据仓库工具**，可以将**结构化的数据文件**映射成一个数据表，注意这里的重点是**结构化的数据文件**。在 HDFS 文件系统中可以存储结构化数据文件，也可以存储非结构化数据文件，而 Hive 是处理其中的结构化数据文件，它本身并不进行存储。

同时，Hive 提供了一套**Hive SQL**实现 MapReduce 计算，我们可以使用与 SQL 十分类似的 Hive SQL 对这些结构化的数据进行统计分析，所以从某种意义上来说 Hive 是对 MapReduce 进行包装后产生的工具。在公司中，Hive 是一个非常常用的数仓工具，很多公司都会把它当作基础数仓来使用。不过 Hive 也有一些不好用的地方，比如不能进行**单条数据更新**。

#### 4.HBase（分布式数据库）

在存储方面，Hadoop 架构中还有一个 Hbase 数据库。HBase 是一个分布式高并发的**K-V 数据库系统**，它的底层当然也是由 HDFS 来支撑，而 HBase 通过对存储内容的重新组织，克服了HDFS 对**小文件处理困难**的问题，实现了数据的实时操作。

在互联网公司中，对于量级较大，且变动较多的数据通常适合使用 HBase 进行存取。比如说我之前所在的做内容的媒体公司，内容数据经常会发生更新等变动，我们对这些内容进行各种算法运算也经常需要单条或者小批量的存取，所以使用 HBase 来存储数据，非常方便。

#### 5.Yarn（资源调度和管理框架）

在最早的 Hadoop 1.0 中其实是没有 Yarn 的，资源调度等功能都包装在 MapReduce 的 JobTracker 中，而 JobTracker 负担了太多的功能，接受任务、资源调度甚至是监控TaskTracker 的运行情况。当时存在一个问题，在集群规模非常大的时候会出现不稳定的情况，于是在 2.0 中对其进行了拆分，因此产生了独立的 Yarn。在拆分出 Yarn 之后，MapReduce 只负责计算，这也给后面其他计算框架替换 MapReduce 提供了方便，保障了 Hadoop 整个架构长盛不衰。

#### 6.ZooKeeper（分布式协作服务）

ZooKeeper，直译是动物园管理员。这是因为很多项目都以动物的名字命名，而 ZooKeeper 最常用的场景是作为一个**服务的注册管理中心**。生产者把所提供的服务提交到 ZooKeeper 中，而消费者则去 ZooKeeper 中寻找自己需要的服务，从中获取生产者的信息，然后再去调用生产者的服务。

在我看来，ZooKeeper 像是一个锁，**把控各种数据流转服务的中间环节**，保障数据的一致性。比如说 HBase、Kafka 等都可以通过 ZooKeeper 进行注册。幸运的是在我们的开发过程中，不需要了解太多 ZooKeeper 的细节，主要是进行一些代码上的配置就可以了。

一口气讲了这么多 Hadoop 的组件，但是可以看到，在 Hadoop 的框架中还远远不止这些东西。不过最主要的、平时工作中接触最多的部分已经都有涉及。

下面我们来看一下 Hadoop 的一些优缺点。

### Hadoop 的优点

**强大的数据存储和处理能力**。这个优点是显而易见的，也是最根本的。通过技术手段，Hadoop 实现了只需要增加一些普通的机器就可以获得强大的存储和运算能力。

**隐藏了大量技术细节**。使用 Hadoop 框架，我们不再需要关注那些复杂的并行计算、负载均衡等内容，只需要调用相关的 API 就可以实现大规模存储和计算。

**良好的扩展能力**。发展到今天，Hadoop 已经不是一个单一的解决方案，它提供了很多不同的组件，不限于我上面列出的这些。公司可以使用标准的方案，也可以根据自己的业务需求来进行细节上的调整甚至是自己的开发。比如说对于计算框架 MapReduce，在很多公司已经使用性能更好的 Spark 或者 Flink 进行了替换。

### Hadoop 的缺点

**实时性较差**。由于 HDFS 存储底层都是在磁盘中进行的，以及原生的 MapReduce 的中间结果也都要存储在磁盘上，所以 Hadoop 的实时性不太好。

**学习难度较大**。虽然说 Hadoop 已经对很多复杂的技术进行了封装，但是仍然挡不住它是一个庞大而复杂的系统。尤其是其中的很多问题都需要在实践中不断摸索，要想学习整个体系几乎是很难在短时间内实现的。

### 总结

这一讲，我为你系统地介绍了一下 Hadoop 体系。虽然处理大数据的框架并不是只有 Hadoop一种，但是 Hadoop 是免费的开源的，而且是当前应用最广泛的。它最强大的地方就在于能够利用最普通的机器解决了大规模数据存储和运算的问题。

![（大数据05.png](https://s0.lgstatic.com/i/image6/M00/04/54/Cgp9HWApKeGAdMPFAAWEYscmKEY957.png)

同时，Hadoop 在经过不断的发展之后也已经形成了自己的生态圈，很多不同的组件都可以与Hadoop 搭配使用。很多公司都基于 Hadoop 框架搭建起了自己的大数据处理体系。目前，免费的 Hadoop 版本主要有三个：

-   一个是 Apache 版本，也就是最原始的发行版；
    
-   一个是 Cloudera 版本，简称 CDH；
    
-   还有一个 Hortonworks 版本，简称 HDP。
    

当然，所有的版本都是基于 Apache 版本进行改进的，而 CDH 版和 HDP 版则附加了很多新的特性，解决了一些工业级应用时的痛点。如果你所在的公司需要做一些这方面的建设，不妨再对几个不同版本进行一下比较。在该过程中有任何问题或者心得，都可以在留言区和我一起探讨。

下一讲我们还会对 Hadoop 生态圈中的一些常用组件进行更加深入的介绍，到时见。

___

[![Drawing 2.png](https://s0.lgstatic.com/i/image6/M00/00/6D/Cgp9HWAaHaOAI85HAAUCrlmIuEw966.png)](https://shenceyun.lagou.com/r/rJs)

**《大数据开发高薪训练营》**

PB 级企业大数据项目实战 + 拉勾硬核内推，5 个月全面掌握大数据核心技能。[点击链接](https://shenceyun.lagou.com/r/rJs)，全面赋能！
